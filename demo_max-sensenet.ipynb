{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sensenet.sensenet import load_sensenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlplab/simon/anaconda3/envs/sensenet/lib/python3.8/site-packages/allennlp/tango/__init__.py:17: UserWarning: AllenNLP Tango is an experimental API and parts of it might change or disappear every time we release a new version.\n",
      "  warnings.warn(\n",
      "2021-12-09 16:52:24,990 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2021-12-09 16:52:24,993 - INFO - allennlp.models.archival - loading archive file data/v0.1.0/wn_bi-camb/sense_embedder/model.tar.gz\n",
      "2021-12-09 16:52:24,993 - INFO - allennlp.models.archival - extracting archive file data/v0.1.0/wn_bi-camb/sense_embedder/model.tar.gz to temp dir /tmp/tmpk9wns7eb\n",
      "2021-12-09 16:52:25,335 - INFO - allennlp.common.params - dataset_reader.type = sense_file\n",
      "2021-12-09 16:52:25,336 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2021-12-09 16:52:25,336 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2021-12-09 16:52:25,337 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2021-12-09 16:52:25,337 - INFO - allennlp.common.params - dataset_reader.tokenizer = whitespace\n",
      "2021-12-09 16:52:25,337 - INFO - allennlp.common.params - type = whitespace\n",
      "2021-12-09 16:52:25,338 - INFO - allennlp.common.params - type = whitespace\n",
      "2021-12-09 16:52:25,338 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.type = ref\n",
      "2021-12-09 16:52:25,340 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.type = single_id\n",
      "2021-12-09 16:52:25,340 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.type = single_id\n",
      "2021-12-09 16:52:25,340 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.namespace = tokens\n",
      "2021-12-09 16:52:25,341 - INFO - allennlp.common.params - type = tokens\n",
      "2021-12-09 16:52:25,341 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.lowercase_tokens = False\n",
      "2021-12-09 16:52:25,341 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.start_tokens = None\n",
      "2021-12-09 16:52:25,341 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.end_tokens = None\n",
      "2021-12-09 16:52:25,342 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.feature_name = text\n",
      "2021-12-09 16:52:25,342 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.default_value = THIS IS A REALLY UNLIKELY VALUE THAT HAS TO BE A STRING\n",
      "2021-12-09 16:52:25,343 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.token_min_padding_length = 0\n",
      "2021-12-09 16:52:25,344 - INFO - allennlp.common.params - dataset_reader.word_indexers.type = ref\n",
      "2021-12-09 16:52:25,344 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.type = single_id\n",
      "2021-12-09 16:52:25,345 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.type = single_id\n",
      "2021-12-09 16:52:25,345 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.namespace = tokens\n",
      "2021-12-09 16:52:25,345 - INFO - allennlp.common.params - type = tokens\n",
      "2021-12-09 16:52:25,346 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.lowercase_tokens = False\n",
      "2021-12-09 16:52:25,346 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.start_tokens = None\n",
      "2021-12-09 16:52:25,346 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.end_tokens = None\n",
      "2021-12-09 16:52:25,346 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.feature_name = text\n",
      "2021-12-09 16:52:25,347 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.default_value = THIS IS A REALLY UNLIKELY VALUE THAT HAS TO BE A STRING\n",
      "2021-12-09 16:52:25,347 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.token_min_padding_length = 0\n",
      "2021-12-09 16:52:25,347 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.type = ref\n",
      "2021-12-09 16:52:25,348 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.type = single_id\n",
      "2021-12-09 16:52:25,350 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.type = single_id\n",
      "2021-12-09 16:52:25,351 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.namespace = output\n",
      "2021-12-09 16:52:25,351 - INFO - allennlp.common.params - type = output\n",
      "2021-12-09 16:52:25,351 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.lowercase_tokens = False\n",
      "2021-12-09 16:52:25,352 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.start_tokens = None\n",
      "2021-12-09 16:52:25,352 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.end_tokens = None\n",
      "2021-12-09 16:52:25,352 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.feature_name = text\n",
      "2021-12-09 16:52:25,352 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.default_value = THIS IS A REALLY UNLIKELY VALUE THAT HAS TO BE A STRING\n",
      "2021-12-09 16:52:25,352 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.token_min_padding_length = 0\n",
      "2021-12-09 16:52:25,353 - INFO - allennlp.common.params - dataset_reader.max_len = 100\n",
      "2021-12-09 16:52:25,353 - INFO - allennlp.common.params - dataset_reader.type = sense_file\n",
      "2021-12-09 16:52:25,353 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2021-12-09 16:52:25,354 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2021-12-09 16:52:25,354 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2021-12-09 16:52:25,354 - INFO - allennlp.common.params - dataset_reader.tokenizer = whitespace\n",
      "2021-12-09 16:52:25,354 - INFO - allennlp.common.params - type = whitespace\n",
      "2021-12-09 16:52:25,355 - INFO - allennlp.common.params - type = whitespace\n",
      "2021-12-09 16:52:25,355 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.type = ref\n",
      "2021-12-09 16:52:25,356 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.type = single_id\n",
      "2021-12-09 16:52:25,356 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.type = single_id\n",
      "2021-12-09 16:52:25,357 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.namespace = tokens\n",
      "2021-12-09 16:52:25,357 - INFO - allennlp.common.params - type = tokens\n",
      "2021-12-09 16:52:25,358 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.lowercase_tokens = False\n",
      "2021-12-09 16:52:25,359 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.start_tokens = None\n",
      "2021-12-09 16:52:25,359 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.end_tokens = None\n",
      "2021-12-09 16:52:25,359 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.feature_name = text\n",
      "2021-12-09 16:52:25,359 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.default_value = THIS IS A REALLY UNLIKELY VALUE THAT HAS TO BE A STRING\n",
      "2021-12-09 16:52:25,360 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.token_min_padding_length = 0\n",
      "2021-12-09 16:52:25,360 - INFO - allennlp.common.params - dataset_reader.word_indexers.type = ref\n",
      "2021-12-09 16:52:25,361 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.type = single_id\n",
      "2021-12-09 16:52:25,361 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.type = single_id\n",
      "2021-12-09 16:52:25,361 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.namespace = tokens\n",
      "2021-12-09 16:52:25,362 - INFO - allennlp.common.params - type = tokens\n",
      "2021-12-09 16:52:25,362 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.lowercase_tokens = False\n",
      "2021-12-09 16:52:25,362 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.start_tokens = None\n",
      "2021-12-09 16:52:25,362 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.end_tokens = None\n",
      "2021-12-09 16:52:25,363 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.feature_name = text\n",
      "2021-12-09 16:52:25,363 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.default_value = THIS IS A REALLY UNLIKELY VALUE THAT HAS TO BE A STRING\n",
      "2021-12-09 16:52:25,363 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.token_min_padding_length = 0\n",
      "2021-12-09 16:52:25,363 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.type = ref\n",
      "2021-12-09 16:52:25,364 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.type = single_id\n",
      "2021-12-09 16:52:25,366 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.type = single_id\n",
      "2021-12-09 16:52:25,366 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.namespace = output\n",
      "2021-12-09 16:52:25,366 - INFO - allennlp.common.params - type = output\n",
      "2021-12-09 16:52:25,367 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.lowercase_tokens = False\n",
      "2021-12-09 16:52:25,367 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.start_tokens = None\n",
      "2021-12-09 16:52:25,367 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.end_tokens = None\n",
      "2021-12-09 16:52:25,368 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.feature_name = text\n",
      "2021-12-09 16:52:25,368 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.default_value = THIS IS A REALLY UNLIKELY VALUE THAT HAS TO BE A STRING\n",
      "2021-12-09 16:52:25,368 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.token_min_padding_length = 0\n",
      "2021-12-09 16:52:25,368 - INFO - allennlp.common.params - dataset_reader.max_len = 100\n",
      "2021-12-09 16:52:25,369 - INFO - allennlp.common.params - vocabulary.type = from_instances\n",
      "2021-12-09 16:52:25,369 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmpk9wns7eb/vocabulary.\n",
      "2021-12-09 16:52:25,390 - INFO - allennlp.common.params - model.type = cpae\n",
      "2021-12-09 16:52:25,390 - INFO - allennlp.common.params - model.word_namespace = tokens\n",
      "2021-12-09 16:52:25,391 - INFO - allennlp.common.params - type = tokens\n",
      "2021-12-09 16:52:25,391 - INFO - allennlp.common.params - model.output_namespace = output\n",
      "2021-12-09 16:52:25,393 - INFO - allennlp.common.params - type = output\n",
      "2021-12-09 16:52:25,393 - INFO - allennlp.common.params - model.def_embedder.type = ref\n",
      "2021-12-09 16:52:25,394 - INFO - allennlp.common.params - model.def_embedder.type = basic\n",
      "2021-12-09 16:52:25,395 - INFO - allennlp.common.params - model.def_embedder.token_embedders.type = ref\n",
      "2021-12-09 16:52:25,396 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.type = embedding\n",
      "2021-12-09 16:52:25,396 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.type = embedding\n",
      "2021-12-09 16:52:25,396 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.embedding_dim = 300\n",
      "2021-12-09 16:52:25,397 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.num_embeddings = None\n",
      "2021-12-09 16:52:25,397 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.projection_dim = None\n",
      "2021-12-09 16:52:25,397 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.weight = None\n",
      "2021-12-09 16:52:25,398 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.padding_index = None\n",
      "2021-12-09 16:52:25,398 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.trainable = False\n",
      "2021-12-09 16:52:25,398 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.max_norm = None\n",
      "2021-12-09 16:52:25,398 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.norm_type = 2.0\n",
      "2021-12-09 16:52:25,399 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.scale_grad_by_freq = False\n",
      "2021-12-09 16:52:25,399 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.sparse = False\n",
      "2021-12-09 16:52:25,399 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.vocab_namespace = tokens\n",
      "2021-12-09 16:52:25,399 - INFO - allennlp.common.params - type = tokens\n",
      "2021-12-09 16:52:25,400 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.pretrained_file = None\n",
      "2021-12-09 16:52:25,438 - INFO - allennlp.common.params - model.encoder.type = lstm\n",
      "2021-12-09 16:52:25,439 - INFO - allennlp.common.params - model.encoder.type = lstm\n",
      "2021-12-09 16:52:25,439 - INFO - allennlp.common.params - model.encoder.input_size = 300\n",
      "2021-12-09 16:52:25,440 - INFO - allennlp.common.params - model.encoder.hidden_size = 300\n",
      "2021-12-09 16:52:25,440 - INFO - allennlp.common.params - model.encoder.num_layers = 1\n",
      "2021-12-09 16:52:25,440 - INFO - allennlp.common.params - model.encoder.bias = True\n",
      "2021-12-09 16:52:25,441 - INFO - allennlp.common.params - model.encoder.dropout = 0.0\n",
      "2021-12-09 16:52:25,441 - INFO - allennlp.common.params - model.encoder.bidirectional = False\n",
      "2021-12-09 16:52:25,443 - INFO - allennlp.common.params - model.alpha = 1\n",
      "2021-12-09 16:52:25,443 - INFO - allennlp.common.params - model.lambda_ = 64\n",
      "2021-12-09 16:52:25,443 - INFO - allennlp.common.params - model.word_embedder = None\n",
      "2021-12-09 16:52:25,490 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpk9wns7eb\n"
     ]
    }
   ],
   "source": [
    "sensenet = load_sensenet('data/v0.1.0/wn_bi-camb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get `Senset`s of a Word with POS Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Senset('apple.NOUN.01'), Senset('apple.NOUN.02')]\n"
     ]
    }
   ],
   "source": [
    "print(sensenet.sensets('apple', 'NOUN'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect `Senset`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sensets(word, pos):\n",
    "    # sensets = senset_table[(word, pos)]\n",
    "    sensets = sensenet.sensets(word, pos)\n",
    "    for senset in sensets:\n",
    "        source_to_senses = group_senses_by_source(senset.senses)\n",
    "        print(senset.senset_id)\n",
    "        print('-' * 50)\n",
    "        for source, senses in source_to_senses.items():\n",
    "            print(f'{source}:')\n",
    "            for sense in senses:\n",
    "                print(f'  - {sense.definition}')\n",
    "            print()\n",
    "        print()\n",
    "    return\n",
    "\n",
    "def group_senses_by_source(senses):\n",
    "    source_to_senses = {}\n",
    "    for sense in senses:\n",
    "        source = sense.source\n",
    "        source_to_senses.setdefault(source, [])\n",
    "        source_to_senses[source].append(sense)\n",
    "    return source_to_senses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple.NOUN.01\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - fruit with red or yellow or green skin and sweet to tart crisp whitish flesh\n",
      "\n",
      "cambridge:\n",
      "  - a round fruit with firm , white flesh and a green , red , or yellow skin\n",
      "\n",
      "\n",
      "apple.NOUN.02\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - native Eurasian tree widely cultivated in many varieties for its firm rounded edible fruits\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_sensets('apple', 'NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mitre.NOUN.01\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - joint that forms a corner ; usually both sides are bevelled at a 45 - degree angle to form a 90 - degree corner\n",
      "\n",
      "cambridge:\n",
      "  - a joint made by two pieces of wood that have both been cut at an angle of 45 Â° at the joining ends\n",
      "\n",
      "\n",
      "mitre.NOUN.02\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - the surface of a beveled end of a piece where a miter joint is made\n",
      "\n",
      "\n",
      "mitre.NOUN.03\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - a liturgical headdress worn by bishops on formal occasions\n",
      "\n",
      "cambridge:\n",
      "  - a tall , pointed hat worn by bishops in official ceremonies\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_sensets('mitre', 'NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baton.NOUN.01\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - a thin tapered rod used by a conductor to lead an orchestra or choir\n",
      "\n",
      "cambridge:\n",
      "  - a stick used by a conductor (= person who controls the performance of a group of musicians ) to show the speed of the music\n",
      "\n",
      "\n",
      "baton.NOUN.02\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - a short stout club used primarily by policemen\n",
      "\n",
      "cambridge:\n",
      "  - a thick , heavy stick used as a weapon by police officers\n",
      "\n",
      "\n",
      "baton.NOUN.03\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - a short staff carried by some officials to symbolize an office or an authority\n",
      "\n",
      "\n",
      "baton.NOUN.04\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - a hollow metal rod that is wielded or twirled by a drum major or drum majorette\n",
      "\n",
      "cambridge:\n",
      "  - a hollow metal stick that a majorette or drum major turns and throws while marching\n",
      "\n",
      "\n",
      "baton.NOUN.05\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - a hollow cylinder passed from runner to runner in a relay race\n",
      "\n",
      "cambridge:\n",
      "  - a stick that is passed from one runner to another in a relay race\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_sensets('baton', 'NOUN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Similar `Senset`s of a `Senset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-09 16:52:45,767 - INFO - gensim.models.keyedvectors - precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senset('fig.NOUN.02') 0.7941373586654663\n",
      "Senset('lemon.NOUN.03') 0.7395809888839722\n",
      "Senset('radish.NOUN.04') 0.737662672996521\n",
      "Senset('turnip.NOUN.01') 0.73208087682724\n",
      "Senset('quince.NOUN.01') 0.7314550280570984\n",
      "Senset('artichoke.NOUN.01') 0.7216981053352356\n",
      "Senset('mango.NOUN.01') 0.7184210419654846\n",
      "Senset('onion.NOUN.02') 0.7169083952903748\n",
      "Senset('carrot.NOUN.02') 0.7150439023971558\n",
      "Senset('spinach.NOUN.01') 0.7146469354629517\n"
     ]
    }
   ],
   "source": [
    "senset = sensenet.senset('apple.NOUN.02')\n",
    "for similar_senset, similarity in senset.similar_sensets():\n",
    "    print(similar_senset, similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senset('crosier.NOUN.01') 0.7406036257743835\n",
      "Senset('cope.NOUN.02') 0.7396152019500732\n",
      "Senset('mitre.NOUN.03') 0.7235139608383179\n",
      "Senset('pontifical.NOUN.01') 0.7155020236968994\n",
      "Senset('archbishop.NOUN.01') 0.6879871487617493\n",
      "Senset('skullcap.NOUN.01') 0.6758203506469727\n",
      "Senset('cathedra.NOUN.01') 0.674426257610321\n",
      "Senset('richmondena.NOUN.01') 0.6690065860748291\n",
      "Senset('episcopate.NOUN.01') 0.6648440957069397\n",
      "Senset('diocese.NOUN.01') 0.6644284725189209\n"
     ]
    }
   ],
   "source": [
    "for senset, similarity in sensenet.reverse_dictionary('bishop hat'):\n",
    "    print(senset, similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
