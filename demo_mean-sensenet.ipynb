{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sensenet.sensenet import load_sensenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlplab/simon/anaconda3/envs/sensenet/lib/python3.8/site-packages/allennlp/tango/__init__.py:17: UserWarning: AllenNLP Tango is an experimental API and parts of it might change or disappear every time we release a new version.\n",
      "  warnings.warn(\n",
      "2021-12-09 17:09:18,429 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2021-12-09 17:09:18,432 - INFO - allennlp.models.archival - loading archive file data/v0.1.0/wn_bi-camb/sense_embedder/model.tar.gz\n",
      "2021-12-09 17:09:18,432 - INFO - allennlp.models.archival - extracting archive file data/v0.1.0/wn_bi-camb/sense_embedder/model.tar.gz to temp dir /tmp/tmphe2bhcbw\n",
      "2021-12-09 17:09:18,773 - INFO - allennlp.common.params - dataset_reader.type = sense_file\n",
      "2021-12-09 17:09:18,773 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2021-12-09 17:09:18,773 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2021-12-09 17:09:18,774 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2021-12-09 17:09:18,774 - INFO - allennlp.common.params - dataset_reader.tokenizer = whitespace\n",
      "2021-12-09 17:09:18,775 - INFO - allennlp.common.params - type = whitespace\n",
      "2021-12-09 17:09:18,775 - INFO - allennlp.common.params - type = whitespace\n",
      "2021-12-09 17:09:18,775 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.type = ref\n",
      "2021-12-09 17:09:18,776 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.type = single_id\n",
      "2021-12-09 17:09:18,777 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.type = single_id\n",
      "2021-12-09 17:09:18,777 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.namespace = tokens\n",
      "2021-12-09 17:09:18,778 - INFO - allennlp.common.params - type = tokens\n",
      "2021-12-09 17:09:18,778 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.lowercase_tokens = False\n",
      "2021-12-09 17:09:18,778 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.start_tokens = None\n",
      "2021-12-09 17:09:18,779 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.end_tokens = None\n",
      "2021-12-09 17:09:18,779 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.feature_name = text\n",
      "2021-12-09 17:09:18,779 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.default_value = THIS IS A REALLY UNLIKELY VALUE THAT HAS TO BE A STRING\n",
      "2021-12-09 17:09:18,780 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.token_min_padding_length = 0\n",
      "2021-12-09 17:09:18,780 - INFO - allennlp.common.params - dataset_reader.word_indexers.type = ref\n",
      "2021-12-09 17:09:18,781 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.type = single_id\n",
      "2021-12-09 17:09:18,781 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.type = single_id\n",
      "2021-12-09 17:09:18,781 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.namespace = tokens\n",
      "2021-12-09 17:09:18,781 - INFO - allennlp.common.params - type = tokens\n",
      "2021-12-09 17:09:18,781 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.lowercase_tokens = False\n",
      "2021-12-09 17:09:18,782 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.start_tokens = None\n",
      "2021-12-09 17:09:18,782 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.end_tokens = None\n",
      "2021-12-09 17:09:18,782 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.feature_name = text\n",
      "2021-12-09 17:09:18,782 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.default_value = THIS IS A REALLY UNLIKELY VALUE THAT HAS TO BE A STRING\n",
      "2021-12-09 17:09:18,782 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.token_min_padding_length = 0\n",
      "2021-12-09 17:09:18,783 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.type = ref\n",
      "2021-12-09 17:09:18,784 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.type = single_id\n",
      "2021-12-09 17:09:18,784 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.type = single_id\n",
      "2021-12-09 17:09:18,785 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.namespace = output\n",
      "2021-12-09 17:09:18,785 - INFO - allennlp.common.params - type = output\n",
      "2021-12-09 17:09:18,785 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.lowercase_tokens = False\n",
      "2021-12-09 17:09:18,785 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.start_tokens = None\n",
      "2021-12-09 17:09:18,786 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.end_tokens = None\n",
      "2021-12-09 17:09:18,786 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.feature_name = text\n",
      "2021-12-09 17:09:18,786 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.default_value = THIS IS A REALLY UNLIKELY VALUE THAT HAS TO BE A STRING\n",
      "2021-12-09 17:09:18,787 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.token_min_padding_length = 0\n",
      "2021-12-09 17:09:18,787 - INFO - allennlp.common.params - dataset_reader.max_len = 100\n",
      "2021-12-09 17:09:18,787 - INFO - allennlp.common.params - dataset_reader.type = sense_file\n",
      "2021-12-09 17:09:18,788 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2021-12-09 17:09:18,788 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2021-12-09 17:09:18,788 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2021-12-09 17:09:18,788 - INFO - allennlp.common.params - dataset_reader.tokenizer = whitespace\n",
      "2021-12-09 17:09:18,789 - INFO - allennlp.common.params - type = whitespace\n",
      "2021-12-09 17:09:18,789 - INFO - allennlp.common.params - type = whitespace\n",
      "2021-12-09 17:09:18,789 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.type = ref\n",
      "2021-12-09 17:09:18,790 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.type = single_id\n",
      "2021-12-09 17:09:18,790 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.type = single_id\n",
      "2021-12-09 17:09:18,791 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.namespace = tokens\n",
      "2021-12-09 17:09:18,791 - INFO - allennlp.common.params - type = tokens\n",
      "2021-12-09 17:09:18,791 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.lowercase_tokens = False\n",
      "2021-12-09 17:09:18,792 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.start_tokens = None\n",
      "2021-12-09 17:09:18,792 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.end_tokens = None\n",
      "2021-12-09 17:09:18,792 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.feature_name = text\n",
      "2021-12-09 17:09:18,792 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.default_value = THIS IS A REALLY UNLIKELY VALUE THAT HAS TO BE A STRING\n",
      "2021-12-09 17:09:18,792 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.token_min_padding_length = 0\n",
      "2021-12-09 17:09:18,793 - INFO - allennlp.common.params - dataset_reader.word_indexers.type = ref\n",
      "2021-12-09 17:09:18,794 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.type = single_id\n",
      "2021-12-09 17:09:18,794 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.type = single_id\n",
      "2021-12-09 17:09:18,794 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.namespace = tokens\n",
      "2021-12-09 17:09:18,795 - INFO - allennlp.common.params - type = tokens\n",
      "2021-12-09 17:09:18,795 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.lowercase_tokens = False\n",
      "2021-12-09 17:09:18,795 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.start_tokens = None\n",
      "2021-12-09 17:09:18,795 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.end_tokens = None\n",
      "2021-12-09 17:09:18,796 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.feature_name = text\n",
      "2021-12-09 17:09:18,796 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.default_value = THIS IS A REALLY UNLIKELY VALUE THAT HAS TO BE A STRING\n",
      "2021-12-09 17:09:18,796 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.token_min_padding_length = 0\n",
      "2021-12-09 17:09:18,796 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.type = ref\n",
      "2021-12-09 17:09:18,797 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.type = single_id\n",
      "2021-12-09 17:09:18,797 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.type = single_id\n",
      "2021-12-09 17:09:18,798 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.namespace = output\n",
      "2021-12-09 17:09:18,798 - INFO - allennlp.common.params - type = output\n",
      "2021-12-09 17:09:18,798 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.lowercase_tokens = False\n",
      "2021-12-09 17:09:18,799 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.start_tokens = None\n",
      "2021-12-09 17:09:18,799 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.end_tokens = None\n",
      "2021-12-09 17:09:18,799 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.feature_name = text\n",
      "2021-12-09 17:09:18,799 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.default_value = THIS IS A REALLY UNLIKELY VALUE THAT HAS TO BE A STRING\n",
      "2021-12-09 17:09:18,799 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.token_min_padding_length = 0\n",
      "2021-12-09 17:09:18,800 - INFO - allennlp.common.params - dataset_reader.max_len = 100\n",
      "2021-12-09 17:09:18,801 - INFO - allennlp.common.params - vocabulary.type = from_instances\n",
      "2021-12-09 17:09:18,801 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmphe2bhcbw/vocabulary.\n",
      "2021-12-09 17:09:18,821 - INFO - allennlp.common.params - model.type = cpae\n",
      "2021-12-09 17:09:18,821 - INFO - allennlp.common.params - model.word_namespace = tokens\n",
      "2021-12-09 17:09:18,821 - INFO - allennlp.common.params - type = tokens\n",
      "2021-12-09 17:09:18,822 - INFO - allennlp.common.params - model.output_namespace = output\n",
      "2021-12-09 17:09:18,822 - INFO - allennlp.common.params - type = output\n",
      "2021-12-09 17:09:18,822 - INFO - allennlp.common.params - model.def_embedder.type = ref\n",
      "2021-12-09 17:09:18,823 - INFO - allennlp.common.params - model.def_embedder.type = basic\n",
      "2021-12-09 17:09:18,823 - INFO - allennlp.common.params - model.def_embedder.token_embedders.type = ref\n",
      "2021-12-09 17:09:18,824 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.type = embedding\n",
      "2021-12-09 17:09:18,824 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.type = embedding\n",
      "2021-12-09 17:09:18,824 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.embedding_dim = 300\n",
      "2021-12-09 17:09:18,825 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.num_embeddings = None\n",
      "2021-12-09 17:09:18,825 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.projection_dim = None\n",
      "2021-12-09 17:09:18,826 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.weight = None\n",
      "2021-12-09 17:09:18,826 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.padding_index = None\n",
      "2021-12-09 17:09:18,826 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.trainable = False\n",
      "2021-12-09 17:09:18,826 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.max_norm = None\n",
      "2021-12-09 17:09:18,826 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.norm_type = 2.0\n",
      "2021-12-09 17:09:18,827 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.scale_grad_by_freq = False\n",
      "2021-12-09 17:09:18,827 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.sparse = False\n",
      "2021-12-09 17:09:18,828 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.vocab_namespace = tokens\n",
      "2021-12-09 17:09:18,828 - INFO - allennlp.common.params - type = tokens\n",
      "2021-12-09 17:09:18,828 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.pretrained_file = None\n",
      "2021-12-09 17:09:18,866 - INFO - allennlp.common.params - model.encoder.type = lstm\n",
      "2021-12-09 17:09:18,866 - INFO - allennlp.common.params - model.encoder.type = lstm\n",
      "2021-12-09 17:09:18,867 - INFO - allennlp.common.params - model.encoder.input_size = 300\n",
      "2021-12-09 17:09:18,867 - INFO - allennlp.common.params - model.encoder.hidden_size = 300\n",
      "2021-12-09 17:09:18,867 - INFO - allennlp.common.params - model.encoder.num_layers = 1\n",
      "2021-12-09 17:09:18,868 - INFO - allennlp.common.params - model.encoder.bias = True\n",
      "2021-12-09 17:09:18,868 - INFO - allennlp.common.params - model.encoder.dropout = 0.0\n",
      "2021-12-09 17:09:18,868 - INFO - allennlp.common.params - model.encoder.bidirectional = False\n",
      "2021-12-09 17:09:18,871 - INFO - allennlp.common.params - model.alpha = 1\n",
      "2021-12-09 17:09:18,871 - INFO - allennlp.common.params - model.lambda_ = 64\n",
      "2021-12-09 17:09:18,872 - INFO - allennlp.common.params - model.word_embedder = None\n",
      "2021-12-09 17:09:18,918 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmphe2bhcbw\n"
     ]
    }
   ],
   "source": [
    "sensenet = load_sensenet('data/v0.1.0/wn_bi-camb',\n",
    "                         sensenet_type='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get `Senset`s of a Word with POS Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Senset('apple.NOUN.01'), Senset('apple.NOUN.02')]\n"
     ]
    }
   ],
   "source": [
    "print(sensenet.sensets('apple', 'NOUN'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect `Senset`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sensets(word, pos):\n",
    "    # sensets = senset_table[(word, pos)]\n",
    "    sensets = sensenet.sensets(word, pos)\n",
    "    for senset in sensets:\n",
    "        source_to_senses = group_senses_by_source(senset.senses)\n",
    "        print(senset.senset_id)\n",
    "        print('-' * 50)\n",
    "        for source, senses in source_to_senses.items():\n",
    "            print(f'{source}:')\n",
    "            for sense in senses:\n",
    "                print(f'  - {sense.definition}')\n",
    "            print()\n",
    "        print()\n",
    "    return\n",
    "\n",
    "def group_senses_by_source(senses):\n",
    "    source_to_senses = {}\n",
    "    for sense in senses:\n",
    "        source = sense.source\n",
    "        source_to_senses.setdefault(source, [])\n",
    "        source_to_senses[source].append(sense)\n",
    "    return source_to_senses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple.NOUN.01\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - fruit with red or yellow or green skin and sweet to tart crisp whitish flesh\n",
      "\n",
      "cambridge:\n",
      "  - a round fruit with firm , white flesh and a green , red , or yellow skin\n",
      "\n",
      "\n",
      "apple.NOUN.02\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - native Eurasian tree widely cultivated in many varieties for its firm rounded edible fruits\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_sensets('apple', 'NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mitre.NOUN.01\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - joint that forms a corner ; usually both sides are bevelled at a 45 - degree angle to form a 90 - degree corner\n",
      "\n",
      "cambridge:\n",
      "  - a joint made by two pieces of wood that have both been cut at an angle of 45 ° at the joining ends\n",
      "\n",
      "\n",
      "mitre.NOUN.02\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - the surface of a beveled end of a piece where a miter joint is made\n",
      "\n",
      "\n",
      "mitre.NOUN.03\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - a liturgical headdress worn by bishops on formal occasions\n",
      "\n",
      "cambridge:\n",
      "  - a tall , pointed hat worn by bishops in official ceremonies\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_sensets('mitre', 'NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baton.NOUN.01\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - a thin tapered rod used by a conductor to lead an orchestra or choir\n",
      "\n",
      "cambridge:\n",
      "  - a stick used by a conductor (= person who controls the performance of a group of musicians ) to show the speed of the music\n",
      "\n",
      "\n",
      "baton.NOUN.02\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - a short stout club used primarily by policemen\n",
      "\n",
      "cambridge:\n",
      "  - a thick , heavy stick used as a weapon by police officers\n",
      "\n",
      "\n",
      "baton.NOUN.03\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - a short staff carried by some officials to symbolize an office or an authority\n",
      "\n",
      "\n",
      "baton.NOUN.04\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - a hollow metal rod that is wielded or twirled by a drum major or drum majorette\n",
      "\n",
      "cambridge:\n",
      "  - a hollow metal stick that a majorette or drum major turns and throws while marching\n",
      "\n",
      "\n",
      "baton.NOUN.05\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - a hollow cylinder passed from runner to runner in a relay race\n",
      "\n",
      "cambridge:\n",
      "  - a stick that is passed from one runner to another in a relay race\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_sensets('baton', 'NOUN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Similar `Senset`s of a `Senset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-09 17:09:31,088 - INFO - gensim.models.keyedvectors - precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senset('fig.NOUN.02') 0.792923092842102\n",
      "Senset('radish.NOUN.04') 0.737662672996521\n",
      "Senset('quince.NOUN.01') 0.7314550280570984\n",
      "Senset('horseradish.NOUN.02') 0.7242127656936646\n",
      "Senset('turnip.NOUN.01') 0.7221769094467163\n",
      "Senset('rowan.NOUN.01') 0.7207340598106384\n",
      "Senset('mango.NOUN.01') 0.7184210419654846\n",
      "Senset('onion.NOUN.02') 0.7169083952903748\n",
      "Senset('pear.NOUN.02') 0.7153394818305969\n",
      "Senset('carrot.NOUN.02') 0.7150439023971558\n"
     ]
    }
   ],
   "source": [
    "senset = sensenet.senset('apple.NOUN.02')\n",
    "for similar_senset, similarity in senset.similar_sensets():\n",
    "    print(similar_senset, similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senset('crosier.NOUN.01') 0.7501304149627686\n",
      "Senset('cope.NOUN.02') 0.7396152019500732\n",
      "Senset('mitre.NOUN.03') 0.7354668378829956\n",
      "Senset('pontifical.NOUN.01') 0.7155020236968994\n",
      "Senset('archbishop.NOUN.01') 0.6752481460571289\n",
      "Senset('cathedra.NOUN.01') 0.674426257610321\n",
      "Senset('surplice.NOUN.01') 0.6743991374969482\n",
      "Senset('skullcap.NOUN.01') 0.6731994152069092\n",
      "Senset('pontiff.NOUN.01') 0.6727056503295898\n",
      "Senset('crozier.NOUN.01') 0.6703187823295593\n"
     ]
    }
   ],
   "source": [
    "for senset, similarity in sensenet.reverse_dictionary('bishop hat'):\n",
    "    print(senset, similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
