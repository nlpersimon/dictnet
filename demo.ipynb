{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sensenet.sensenet.sensenet import SenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlplab/simon/anaconda3/envs/sensenet/lib/python3.8/site-packages/allennlp/tango/__init__.py:17: UserWarning: AllenNLP Tango is an experimental API and parts of it might change or disappear every time we release a new version.\n",
      "  warnings.warn(\n",
      "2021-12-02 15:30:08,505 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2021-12-02 15:30:08,514 - INFO - allennlp.models.archival - loading archive file data/v0.0.1/wn_bi-camb/wn_bi-camb_cpae/model.tar.gz\n",
      "2021-12-02 15:30:08,516 - INFO - allennlp.models.archival - extracting archive file data/v0.0.1/wn_bi-camb/wn_bi-camb_cpae/model.tar.gz to temp dir /tmp/tmpjwq3_kza\n",
      "2021-12-02 15:30:08,968 - INFO - allennlp.common.params - dataset_reader.type = sense_file\n",
      "2021-12-02 15:30:08,969 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2021-12-02 15:30:08,970 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2021-12-02 15:30:08,970 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2021-12-02 15:30:08,971 - INFO - allennlp.common.params - dataset_reader.tokenizer = whitespace\n",
      "2021-12-02 15:30:08,972 - INFO - allennlp.common.params - type = whitespace\n",
      "2021-12-02 15:30:08,972 - INFO - allennlp.common.params - type = whitespace\n",
      "2021-12-02 15:30:08,973 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.type = ref\n",
      "2021-12-02 15:30:08,976 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.type = single_id\n",
      "2021-12-02 15:30:08,977 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.type = single_id\n",
      "2021-12-02 15:30:08,977 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.namespace = tokens\n",
      "2021-12-02 15:30:08,978 - INFO - allennlp.common.params - type = tokens\n",
      "2021-12-02 15:30:08,979 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.lowercase_tokens = False\n",
      "2021-12-02 15:30:08,979 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.start_tokens = None\n",
      "2021-12-02 15:30:08,979 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.end_tokens = None\n",
      "2021-12-02 15:30:08,980 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.feature_name = text\n",
      "2021-12-02 15:30:08,980 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.default_value = THIS IS A REALLY UNLIKELY VALUE THAT HAS TO BE A STRING\n",
      "2021-12-02 15:30:08,984 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.token_min_padding_length = 0\n",
      "2021-12-02 15:30:08,985 - INFO - allennlp.common.params - dataset_reader.word_indexers.type = ref\n",
      "2021-12-02 15:30:08,987 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.type = single_id\n",
      "2021-12-02 15:30:08,987 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.type = single_id\n",
      "2021-12-02 15:30:08,988 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.namespace = tokens\n",
      "2021-12-02 15:30:08,988 - INFO - allennlp.common.params - type = tokens\n",
      "2021-12-02 15:30:08,989 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.lowercase_tokens = False\n",
      "2021-12-02 15:30:08,989 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.start_tokens = None\n",
      "2021-12-02 15:30:08,989 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.end_tokens = None\n",
      "2021-12-02 15:30:08,990 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.feature_name = text\n",
      "2021-12-02 15:30:08,991 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.default_value = THIS IS A REALLY UNLIKELY VALUE THAT HAS TO BE A STRING\n",
      "2021-12-02 15:30:08,991 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.token_min_padding_length = 0\n",
      "2021-12-02 15:30:08,992 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.type = ref\n",
      "2021-12-02 15:30:08,993 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.type = single_id\n",
      "2021-12-02 15:30:08,994 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.type = single_id\n",
      "2021-12-02 15:30:08,994 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.namespace = output\n",
      "2021-12-02 15:30:08,995 - INFO - allennlp.common.params - type = output\n",
      "2021-12-02 15:30:08,995 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.lowercase_tokens = False\n",
      "2021-12-02 15:30:08,996 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.start_tokens = None\n",
      "2021-12-02 15:30:08,997 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.end_tokens = None\n",
      "2021-12-02 15:30:08,997 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.feature_name = text\n",
      "2021-12-02 15:30:08,998 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.default_value = THIS IS A REALLY UNLIKELY VALUE THAT HAS TO BE A STRING\n",
      "2021-12-02 15:30:08,999 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.token_min_padding_length = 0\n",
      "2021-12-02 15:30:09,001 - INFO - allennlp.common.params - dataset_reader.max_len = 100\n",
      "2021-12-02 15:30:09,001 - INFO - allennlp.common.params - dataset_reader.type = sense_file\n",
      "2021-12-02 15:30:09,002 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2021-12-02 15:30:09,003 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2021-12-02 15:30:09,003 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2021-12-02 15:30:09,004 - INFO - allennlp.common.params - dataset_reader.tokenizer = whitespace\n",
      "2021-12-02 15:30:09,005 - INFO - allennlp.common.params - type = whitespace\n",
      "2021-12-02 15:30:09,005 - INFO - allennlp.common.params - type = whitespace\n",
      "2021-12-02 15:30:09,006 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.type = ref\n",
      "2021-12-02 15:30:09,008 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.type = single_id\n",
      "2021-12-02 15:30:09,009 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.type = single_id\n",
      "2021-12-02 15:30:09,010 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.namespace = tokens\n",
      "2021-12-02 15:30:09,010 - INFO - allennlp.common.params - type = tokens\n",
      "2021-12-02 15:30:09,011 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.lowercase_tokens = False\n",
      "2021-12-02 15:30:09,011 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.start_tokens = None\n",
      "2021-12-02 15:30:09,012 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.end_tokens = None\n",
      "2021-12-02 15:30:09,012 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.feature_name = text\n",
      "2021-12-02 15:30:09,013 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.default_value = THIS IS A REALLY UNLIKELY VALUE THAT HAS TO BE A STRING\n",
      "2021-12-02 15:30:09,013 - INFO - allennlp.common.params - dataset_reader.input_token_indexers.tokens.token_min_padding_length = 0\n",
      "2021-12-02 15:30:09,014 - INFO - allennlp.common.params - dataset_reader.word_indexers.type = ref\n",
      "2021-12-02 15:30:09,016 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.type = single_id\n",
      "2021-12-02 15:30:09,017 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.type = single_id\n",
      "2021-12-02 15:30:09,018 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.namespace = tokens\n",
      "2021-12-02 15:30:09,019 - INFO - allennlp.common.params - type = tokens\n",
      "2021-12-02 15:30:09,020 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.lowercase_tokens = False\n",
      "2021-12-02 15:30:09,020 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.start_tokens = None\n",
      "2021-12-02 15:30:09,021 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.end_tokens = None\n",
      "2021-12-02 15:30:09,022 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.feature_name = text\n",
      "2021-12-02 15:30:09,022 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.default_value = THIS IS A REALLY UNLIKELY VALUE THAT HAS TO BE A STRING\n",
      "2021-12-02 15:30:09,023 - INFO - allennlp.common.params - dataset_reader.word_indexers.tokens.token_min_padding_length = 0\n",
      "2021-12-02 15:30:09,024 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.type = ref\n",
      "2021-12-02 15:30:09,026 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.type = single_id\n",
      "2021-12-02 15:30:09,027 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.type = single_id\n",
      "2021-12-02 15:30:09,028 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.namespace = output\n",
      "2021-12-02 15:30:09,029 - INFO - allennlp.common.params - type = output\n",
      "2021-12-02 15:30:09,029 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.lowercase_tokens = False\n",
      "2021-12-02 15:30:09,030 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.start_tokens = None\n",
      "2021-12-02 15:30:09,030 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.end_tokens = None\n",
      "2021-12-02 15:30:09,031 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.feature_name = text\n",
      "2021-12-02 15:30:09,032 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.default_value = THIS IS A REALLY UNLIKELY VALUE THAT HAS TO BE A STRING\n",
      "2021-12-02 15:30:09,032 - INFO - allennlp.common.params - dataset_reader.output_token_indexers.output.token_min_padding_length = 0\n",
      "2021-12-02 15:30:09,033 - INFO - allennlp.common.params - dataset_reader.max_len = 100\n",
      "2021-12-02 15:30:09,034 - INFO - allennlp.common.params - vocabulary.type = from_instances\n",
      "2021-12-02 15:30:09,035 - INFO - allennlp.data.vocabulary - Loading token dictionary from /tmp/tmpjwq3_kza/vocabulary.\n",
      "2021-12-02 15:30:09,089 - INFO - allennlp.common.params - model.type = cpae\n",
      "2021-12-02 15:30:09,090 - INFO - allennlp.common.params - model.word_namespace = tokens\n",
      "2021-12-02 15:30:09,091 - INFO - allennlp.common.params - type = tokens\n",
      "2021-12-02 15:30:09,092 - INFO - allennlp.common.params - model.output_namespace = output\n",
      "2021-12-02 15:30:09,094 - INFO - allennlp.common.params - type = output\n",
      "2021-12-02 15:30:09,095 - INFO - allennlp.common.params - model.def_embedder.type = ref\n",
      "2021-12-02 15:30:09,097 - INFO - allennlp.common.params - model.def_embedder.type = basic\n",
      "2021-12-02 15:30:09,098 - INFO - allennlp.common.params - model.def_embedder.token_embedders.type = ref\n",
      "2021-12-02 15:30:09,099 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.type = embedding\n",
      "2021-12-02 15:30:09,100 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.type = embedding\n",
      "2021-12-02 15:30:09,100 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.embedding_dim = 300\n",
      "2021-12-02 15:30:09,101 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.num_embeddings = None\n",
      "2021-12-02 15:30:09,101 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.projection_dim = None\n",
      "2021-12-02 15:30:09,102 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.weight = None\n",
      "2021-12-02 15:30:09,102 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.padding_index = None\n",
      "2021-12-02 15:30:09,103 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.trainable = False\n",
      "2021-12-02 15:30:09,103 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.max_norm = None\n",
      "2021-12-02 15:30:09,104 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.norm_type = 2.0\n",
      "2021-12-02 15:30:09,104 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.scale_grad_by_freq = False\n",
      "2021-12-02 15:30:09,105 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.sparse = False\n",
      "2021-12-02 15:30:09,105 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.vocab_namespace = tokens\n",
      "2021-12-02 15:30:09,106 - INFO - allennlp.common.params - type = tokens\n",
      "2021-12-02 15:30:09,106 - INFO - allennlp.common.params - model.def_embedder.token_embedders.tokens.pretrained_file = None\n",
      "2021-12-02 15:30:09,177 - INFO - allennlp.common.params - model.encoder.type = lstm\n",
      "2021-12-02 15:30:09,178 - INFO - allennlp.common.params - model.encoder.type = lstm\n",
      "2021-12-02 15:30:09,179 - INFO - allennlp.common.params - model.encoder.input_size = 300\n",
      "2021-12-02 15:30:09,179 - INFO - allennlp.common.params - model.encoder.hidden_size = 300\n",
      "2021-12-02 15:30:09,180 - INFO - allennlp.common.params - model.encoder.num_layers = 1\n",
      "2021-12-02 15:30:09,180 - INFO - allennlp.common.params - model.encoder.bias = True\n",
      "2021-12-02 15:30:09,181 - INFO - allennlp.common.params - model.encoder.dropout = 0.0\n",
      "2021-12-02 15:30:09,181 - INFO - allennlp.common.params - model.encoder.bidirectional = False\n",
      "2021-12-02 15:30:09,195 - INFO - allennlp.common.params - model.alpha = 1\n",
      "2021-12-02 15:30:09,196 - INFO - allennlp.common.params - model.lambda_ = 64\n",
      "2021-12-02 15:30:09,197 - INFO - allennlp.common.params - model.word_embedder = None\n",
      "2021-12-02 15:30:09,275 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /tmp/tmpjwq3_kza\n"
     ]
    }
   ],
   "source": [
    "sensenet = SenseNet.from_path('data/v0.0.1/wn_bi-camb/senset_file_bi-camb.jsonl',\n",
    "                              'data/v0.0.1/wn_bi-camb/wn_bi-camb_cpae.txt',\n",
    "                              'data/v0.0.1/wn_bi-camb/wn_bi-camb_cpae/model.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get `Senset`s of a Word with POS Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Senset('apple.NOUN.01'), Senset('apple.NOUN.02')]\n"
     ]
    }
   ],
   "source": [
    "print(sensenet.sensets('apple', 'NOUN'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect `Senset`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sensets(word, pos):\n",
    "    # sensets = senset_table[(word, pos)]\n",
    "    sensets = sensenet.sensets(word, pos)\n",
    "    for senset in sensets:\n",
    "        source_to_senses = group_senses_by_source(senset.senses)\n",
    "        print(senset.senset_id)\n",
    "        print('-' * 50)\n",
    "        for source, senses in source_to_senses.items():\n",
    "            print(f'{source}:')\n",
    "            for sense in senses:\n",
    "                print(f'  - {sense.definition}')\n",
    "            print()\n",
    "        print()\n",
    "    return\n",
    "\n",
    "def group_senses_by_source(senses):\n",
    "    source_to_senses = {}\n",
    "    for sense in senses:\n",
    "        source = sense.source\n",
    "        source_to_senses.setdefault(source, [])\n",
    "        source_to_senses[source].append(sense)\n",
    "    return source_to_senses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple.NOUN.01\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - fruit with red or yellow or green skin and sweet to tart crisp whitish flesh\n",
      "\n",
      "cambridge:\n",
      "  - a round fruit with firm , white flesh and a green , red , or yellow skin\n",
      "\n",
      "\n",
      "apple.NOUN.02\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - native Eurasian tree widely cultivated in many varieties for its firm rounded edible fruits\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_sensets('apple', 'NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mitre.NOUN.01\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - joint that forms a corner ; usually both sides are bevelled at a 45 - degree angle to form a 90 - degree corner\n",
      "\n",
      "cambridge:\n",
      "  - a joint made by two pieces of wood that have both been cut at an angle of 45 ° at the joining ends\n",
      "\n",
      "\n",
      "mitre.NOUN.02\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - the surface of a beveled end of a piece where a miter joint is made\n",
      "\n",
      "\n",
      "mitre.NOUN.03\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - a liturgical headdress worn by bishops on formal occasions\n",
      "\n",
      "cambridge:\n",
      "  - a tall , pointed hat worn by bishops in official ceremonies\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_sensets('mitre', 'NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baton.NOUN.01\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - a thin tapered rod used by a conductor to lead an orchestra or choir\n",
      "\n",
      "cambridge:\n",
      "  - a stick used by a conductor (= person who controls the performance of a group of musicians ) to show the speed of the music\n",
      "\n",
      "\n",
      "baton.NOUN.02\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - a short stout club used primarily by policemen\n",
      "\n",
      "cambridge:\n",
      "  - a thick , heavy stick used as a weapon by police officers\n",
      "\n",
      "\n",
      "baton.NOUN.03\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - a short staff carried by some officials to symbolize an office or an authority\n",
      "\n",
      "\n",
      "baton.NOUN.04\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - a hollow metal rod that is wielded or twirled by a drum major or drum majorette\n",
      "\n",
      "cambridge:\n",
      "  - a hollow metal stick that a majorette or drum major turns and throws while marching\n",
      "\n",
      "\n",
      "baton.NOUN.05\n",
      "--------------------------------------------------\n",
      "wordnet:\n",
      "  - a hollow cylinder passed from runner to runner in a relay race\n",
      "\n",
      "cambridge:\n",
      "  - a stick that is passed from one runner to another in a relay race\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_sensets('baton', 'NOUN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Similar `Senset`s of a `Senset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-02 15:30:42,238 - INFO - gensim.models.keyedvectors - precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senset('fig.NOUN.02') 0.7941375374794006\n",
      "Senset('lemon.NOUN.03') 0.7395809888839722\n",
      "Senset('radish.NOUN.04') 0.7376625537872314\n",
      "Senset('turnip.NOUN.01') 0.7320808172225952\n",
      "Senset('quince.NOUN.01') 0.7314552068710327\n",
      "Senset('artichoke.NOUN.01') 0.7216981649398804\n",
      "Senset('mango.NOUN.01') 0.7184211015701294\n",
      "Senset('onion.NOUN.02') 0.7169082760810852\n",
      "Senset('carrot.NOUN.02') 0.7150439023971558\n",
      "Senset('spinach.NOUN.01') 0.7146469354629517\n"
     ]
    }
   ],
   "source": [
    "senset = sensenet.senset('apple.NOUN.02')\n",
    "for similar_senset, similarity in senset.similar_sensets():\n",
    "    print(similar_senset, similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senset('crosier.NOUN.01') 0.7406036853790283\n",
      "Senset('cope.NOUN.02') 0.7396151423454285\n",
      "Senset('mitre.NOUN.03') 0.7235138416290283\n",
      "Senset('pontifical.NOUN.01') 0.7155019640922546\n",
      "Senset('archbishop.NOUN.01') 0.6879871487617493\n",
      "Senset('skullcap.NOUN.01') 0.6758203506469727\n",
      "Senset('cathedra.NOUN.01') 0.6744264364242554\n",
      "Senset('richmondena.NOUN.01') 0.6690065860748291\n",
      "Senset('episcopate.NOUN.01') 0.6648440361022949\n",
      "Senset('diocese.NOUN.01') 0.6644286513328552\n"
     ]
    }
   ],
   "source": [
    "for senset, similarity in sensenet.reverse_dictionary('bishop hat'):\n",
    "    print(senset, similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
